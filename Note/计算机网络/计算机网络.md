# 计算机网络

## 1.我们的底层链路最终是通过 MAC 地址找到目标主机的，那么 IP 如何转换成 MAC 地址？

ARP 协议，当一台计算机知道目标主机的 IP 地址，而不知道其 MAC 地址时，会通过 ARP 请求广播到网络中：

1. 此时会像当前局域网广播一个 ARP 包，询问谁拥有这个 IP 地址？
2. 目标主机收到请求后，会发送一个 ARP 响应包，里面包含他的 MAC 地址。
3. 发送者收到 ARP 响应后，会将目标主机的 IP 地址和 MAC 地址存入 ARP 缓存。

ARP 协议并不基于任何协议，它属于数据链路层协议，当需要跨网络（不在同一局域网内），路由器会先根据目标 IP 地址进行路由选择。

## 2. 键入网址到页面显示发生了什么？

1. 第一步是解析 URL，**生成**我们需要发送给 web 服务器的请求信息，相当于输入（input），比如协议，web 服务器（地址），路径，文件等。

2. 此时我们得到了 web 服务器地址，比如说 www.baidu.com 这样的地址，我们需要将他解析成 IP 地址才可以去进行访问，我们本机虽然会有缓存，但是肯定无法存储所有域名对应的 IP 地址，此时就需要去向专门的 DNS 服务器去查询指定域名的服务器地址。

   此时额外需要注意的就是我们的域名以 `.` 分割，这就代表了层级，先向根 DNS 服务器查询 `.com` 的地址，再去 `.com` 服务器查询 `.baidu` 的地址，这样最终就找到了我们想要访问的服务器的地址。

3. http 调用套接字，通过 tcp 实现可靠传输。

4. 将源地址，目标地址，协议号（如 TCP）填入 IP 包头，生成 IP 报文。

5. 然后我们需要加上 MAC 头部，需要将目标 MAC 地址，源 MAC 地址，协议号填入，目标地址可以通过本地的 ARP 缓存表查询，如果本地没有，可以通过 ARP 协议获取目标地址的 MAC 地址。

6. 最后，包头加上起始帧分界符，包尾加上 `FCS` 帧校验序列之后，我们需要通过网卡就将一系列二进制数据转换为电信号发送出去。

7. 中途，交换机中，电信号会被转换为数字信号，校验错误，然后放入缓冲区，通过包头的目标端口转发到对应的交换机端口从而发送到链路中。

8. 经过路由器，它具有三层，具有 MAC 地址和 IP 地址，而交换机没有，所以他会对包头的 MAC 地址进行检验，不是发给自己的就丢弃，然后去掉 MAC 头部，根据 IP 头部信息进行转发。

   我们在途中每经过一个路由或者主机，都需要进行一次路由选择算法选择对应的 IP，然后通过 ARP 缓存表或者 ARP 协议获取对应 IP 的 MAC 地址，以此来转发包。

9. 到达服务器，去除一系列包头，到达应用层。

## 3. LINUX 的收发网络包

由于单纯依赖中断来检测网络数据包是否到达的效率过低，Linux 引入了 NAPI 机制，当数据包过多时，会先暂时屏蔽中断，而采用轮询的机制，定期检查是否有新数据包的到达。

## 4. Ping 和 traceroute？

Ping 和 traceroute 都是基于 ICMP 协议工作的，而 ICMP 基于 IP 协议实现，由 IP 报头封装，属于网络层协议，可以向发送方返回错误信息，可以确认 IP 包是否送达目标地址，IP 包被丢弃的原因等，比如在数据包传输阶段通过 ARP 协议获取 MAC 地址失败，就会返回一个 ICMP 目标不可达数据包，其他类型的还有 TTL 降为零超时，端口未监听，找不到 IP，报文未分片等等。

traceroute 主要是通过设置特殊的 ttl 来强制接受 ICMP 超时信息来拿到所有路由器的 IP，当然，有些路由器会保护自己的 IP，此时就会显示替换为 `*` ，并且 traceroute 会填入一个不可能的端口号作为目标端口，一旦接收到端口不可达的信息，就说明我们的发出的包到达了目标主机。

traceroute 的另一个作用是当前不知道数据链路的 MTU 是多少，从而去确定路径的 MTU，以便能到达目标主机。

## 5. 0.0.0.0，localhost，127.0.0.1 到底有什么区别？

localhost 实际上是一个域名，但是默认会将其解析为 127.0.0.1，而 127.0.0.1 叫做回环地址，如果 ping 它的话，就会在本机网络协议栈转一圈回来，而我们 ping 本机地址也是一样的，而 0.0.0.0 在监听的时候代表的是本机 IPV4 的所有地址，而在 ping 的时候，表示的是无效地址。

## 6. HTTP1.1 -> HTTP2 -> HTTP3？

HTTP2 相对于 HTTP1.1 做了大量优化：

HTTP2 首先采用了二进制帧格式，将原本整体传输的 HTTP 请求划分为多个具有固定结构的帧。多个 Stream 的帧可以在同一个 TCP 连接中交错传输，而同一个 Stream 内的帧仍保持顺序（一个请求只能在一个 stream 中传输），在对端再进行重组。这种分帧机制允许多个请求并发地共享一个连接，从而实现真正的多路复用，解决了 HTTP1.1 中由于串行请求导致的应用层队头阻塞问题。

此外，HTTP2 使用 HPACK 头部压缩算法，通过静态表和动态表对重复的 Header 字段进行索引化和压缩，大幅减少了头部体积，降低了网络传输开销。

尽管如此，HTTP2 依旧有着接收端的 tcp 队头阻塞问题，tls + tcp 三次握手的大量开销以及同一客户端在切换网络时需要重新建立连接的开销，在 HTTP3 中，这些问题得到了解决。

HTTP3 将传输层换成了 udp，同时在 UDP 的基础上的 QUIC 协议进行开发的，QUIC 协议将 tls1.3 集成到内部握手流程，同时无传输层队头阻塞问题，不依靠四元组重连的特性（同一客户端的连接快速迁移），同时也实现了 HTTP2 的流式传输。因此解决了以上的所有问题。

除此之外，HTTP/3 使用 QPACK 作为头部压缩算法。QPACK 基于 HPACK 的理念（静态表 + 动态表），其静态表的字段更多，意味着头部能得到更加充分的压缩；针对于动态表，由于请求的流是乱序的，所以难以依靠之前发送的请求的 header 生成的动态表来进行解析（因为 HTTP2 至少是有序到达对端的，所以不会有这种问题），所以 QUIC 设计了一个双向流用于同步双方的动态表的映射 KV，从而确保头部压缩在乱序环境下也能无阻塞地工作。

## 7. TCP 的流量控制和拥塞控制？

TCP 协议中，发送方在发送消息是需要考虑到接收方的接受能力来控制实际发送的数据量，这就是流量控制。

**为什么需要流量控制？** 如果发送方不考虑接收方的接受能力，不停地发送大量的数据包，就会导致对端无法在高负荷的情况下接受所有数据，因此就会丢弃从而触发重传机制，进而导致大量的带宽浪费。

TCP 的消息头有一个字段就是用于通知窗口大小的，接收端会将自己可用的接收数据缓冲区写入伴随 ack 返回给发送端。**那如果窗口满了咋办？** 此时发送方会时不时发送一个窗口探测报文来获悉最新的窗口大小。

然而，流量控制并不是说就是十全十美的，当接收端的处理能力跟不上时，窗口大小会不断减少，最终，当窗口大小缩小至 100 字节，甚至更小，引发的问题就是 TCP 每次发送数据只能发送很小的数据报，从而导致头部开销增大，因此引入了 Nagle 算法，在对端缓冲区小于一定数值的时候，接收端在返回 ack 的时候会通知对端当前窗口大小为 0 从而发送端就无法发送数据，直到接收端缓冲区大于一定阈值，发送端才可以发送数据，这就避免了大量的小数据报的开销。提高了网络利用率。