# 计算机网络

## 1.我们的底层链路最终是通过 MAC 地址找到目标主机的，那么 IP 如何转换成 MAC 地址？

ARP 协议，当一台计算机知道目标主机的 IP 地址，而不知道其 MAC 地址时，会通过 ARP 请求广播到网络中：

1. 此时会像当前局域网广播一个 ARP 包，询问谁拥有这个 IP 地址？
2. 目标主机收到请求后，会发送一个 ARP 响应包，里面包含他的 MAC 地址。
3. 发送者收到 ARP 响应后，会将目标主机的 IP 地址和 MAC 地址存入 ARP 缓存。

ARP 协议并不基于任何协议，它属于数据链路层协议，当需要跨网络（不在同一局域网内），路由器会先根据目标 IP 地址进行路由选择。

## 2. 键入网址到页面显示发生了什么？

1. 第一步是解析 URL，**生成**我们需要发送给 web 服务器的请求信息，相当于输入（input），比如协议，web 服务器（地址），路径，文件等。

2. 此时我们得到了 web 服务器地址，比如说 www.baidu.com 这样的地址，我们需要将他解析成 IP 地址才可以去进行访问，我们本机虽然会有缓存，但是肯定无法存储所有域名对应的 IP 地址，此时就需要去向专门的 DNS 服务器去查询指定域名的服务器地址。

   此时额外需要注意的就是我们的域名以 `.` 分割，这就代表了层级，先向根 DNS 服务器查询 `.com` 的地址，再去 `.com` 服务器查询 `.baidu` 的地址，这样最终就找到了我们想要访问的服务器的地址。

3. http 调用套接字，通过 tcp 实现可靠传输。

4. 将源地址，目标地址，协议号（如 TCP）填入 IP 包头，生成 IP 报文。

5. 然后我们需要加上 MAC 头部，需要将目标 MAC 地址，源 MAC 地址，协议号填入，目标地址可以通过本地的 ARP 缓存表查询，如果本地没有，可以通过 ARP 协议获取目标地址的 MAC 地址。

6. 最后，包头加上起始帧分界符，包尾加上 `FCS` 帧校验序列之后，我们需要通过网卡就将一系列二进制数据转换为电信号发送出去。

7. 中途，交换机中，电信号会被转换为数字信号，校验错误，然后放入缓冲区，通过包头的目标端口转发到对应的交换机端口从而发送到链路中。

8. 经过路由器，它具有三层，具有 MAC 地址和 IP 地址，而交换机没有，所以他会对包头的 MAC 地址进行检验，不是发给自己的就丢弃，然后去掉 MAC 头部，根据 IP 头部信息进行转发。

   我们在途中每经过一个路由或者主机，都需要进行一次路由选择算法选择对应的 IP，然后通过 ARP 缓存表或者 ARP 协议获取对应 IP 的 MAC 地址，以此来转发包。

9. 到达服务器，去除一系列包头，到达应用层。

## 3. LINUX 的收发网络包

由于单纯依赖中断来检测网络数据包是否到达的效率过低，Linux 引入了 NAPI 机制，当数据包过多时，会先暂时屏蔽中断，而采用轮询的机制，定期检查是否有新数据包的到达。

## 4. Ping 和 traceroute？

Ping 和 traceroute 都是基于 ICMP 协议工作的，而 ICMP 基于 IP 协议实现，由 IP 报头封装，属于网络层协议，可以向发送方返回错误信息，可以确认 IP 包是否送达目标地址，IP 包被丢弃的原因等，比如在数据包传输阶段通过 ARP 协议获取 MAC 地址失败，就会返回一个 ICMP 目标不可达数据包，其他类型的还有 TTL 降为零超时，端口未监听，找不到 IP，报文未分片等等。

traceroute 主要是通过设置特殊的 ttl 来强制接受 ICMP 超时信息来拿到所有路由器的 IP，当然，有些路由器会保护自己的 IP，此时就会显示替换为 `*` ，并且 traceroute 会填入一个不可能的端口号作为目标端口，一旦接收到端口不可达的信息，就说明我们的发出的包到达了目标主机。

traceroute 的另一个作用是当前不知道数据链路的 MTU 是多少，从而去确定路径的 MTU，以便能到达目标主机。

## 5. 0.0.0.0，localhost，127.0.0.1 到底有什么区别？

localhost 实际上是一个域名，但是默认会将其解析为 127.0.0.1，而 127.0.0.1 叫做回环地址，如果 ping 它的话，就会在本机网络协议栈转一圈回来，而我们 ping 本机地址也是一样的，而 0.0.0.0 在监听的时候代表的是本机 IPV4 的所有地址，而在 ping 的时候，表示的是无效地址。

## 6. HTTP1.1 -> HTTP2 -> HTTP3？

HTTP2 相对于 HTTP1.1 做了大量优化：

HTTP2 首先采用了二进制帧格式，将原本整体传输的 HTTP 请求划分为多个具有固定结构的帧。多个 Stream 的帧可以在同一个 TCP 连接中交错传输，而同一个 Stream 内的帧仍保持顺序（一个请求只能在一个 stream 中传输），在对端再进行重组。这种分帧机制允许多个请求并发地共享一个连接，从而实现真正的多路复用，解决了 HTTP1.1 中由于串行请求导致的应用层队头阻塞问题。

此外，HTTP2 使用 HPACK 头部压缩算法，通过静态表和动态表对重复的 Header 字段进行索引化和压缩，大幅减少了头部体积，降低了网络传输开销。

尽管如此，HTTP2 依旧有着接收端的 tcp 队头阻塞问题，tls + tcp 三次握手的大量开销以及同一客户端在切换网络时需要重新建立连接的开销，在 HTTP3 中，这些问题得到了解决。

HTTP3 将传输层换成了 udp，同时在 UDP 的基础上的 QUIC 协议进行开发的，QUIC 协议将 tls1.3 集成到内部握手流程，同时无传输层队头阻塞问题，不依靠四元组重连的特性（同一客户端的连接快速迁移），同时也实现了 HTTP2 的流式传输。因此解决了以上的所有问题。

除此之外，HTTP/3 使用 QPACK 作为头部压缩算法。QPACK 基于 HPACK 的理念（静态表 + 动态表），其静态表的字段更多，意味着头部能得到更加充分的压缩；针对于动态表，由于请求的流是乱序的，所以难以依靠之前发送的请求的 header 生成的动态表来进行解析（因为 HTTP2 至少是有序到达对端的，所以不会有这种问题），所以 QUIC 设计了一个双向流用于同步双方的动态表的映射 KV，从而确保头部压缩在乱序环境下也能无阻塞地工作。

## 7. TCP 的流量控制和拥塞控制？

TCP 协议中，发送方在发送消息是需要考虑到接收方的接受能力来控制实际发送的数据量，这就是流量控制。

**为什么需要流量控制？** 如果发送方不考虑接收方的接受能力，不停地发送大量的数据包，就会导致对端无法在高负荷的情况下接受所有数据，因此就会丢弃从而触发重传机制，进而导致大量的带宽浪费。

TCP 的消息头有一个字段就是用于通知窗口大小的，接收端会将自己可用的接收数据缓冲区写入伴随 ack 返回给发送端。**那如果窗口满了咋办？** 此时发送方会时不时发送一个窗口探测报文来获悉最新的窗口大小。

然而，流量控制并不是说就是十全十美的，当接收端的处理能力跟不上时，窗口大小会不断减少，最终，当窗口大小缩小至 100 字节，甚至更小，引发的问题就是 TCP 每次发送数据只能发送很小的数据报，从而导致头部开销增大，因此引入了 Nagle 算法，在对端缓冲区小于一定数值并且受到了之前发送的数据包的 ack 的时候，接收端在返回 ack 的时候会通知对端当前窗口大小为 0 从而发送端就无法发送数据，直到接收端缓冲区大于一定阈值，发送端才可以发送数据，当然不会一直阻塞下去，会有一个超时时间，如果延迟时间过长就会直接发送，这就避免了大量的小数据报的开销。提高了网络利用率。

**拥塞控制又是什么？** TCP 协议中，既然有一个窗口控制，意味着我们可以不等待应答就可以直接发送下一段数据，这也就意味着我们需要控制 TCP 报文的发送速度，我们如果设置为一个定值，设置得太小会导致网络资源利用不充分，太大又会导致不同时段的网络拥堵，容易超时，因此有了**拥塞控制**：
	1. 首先，TCP 在通信最开始会通过慢启动来对发送的数据量进行控制，这里定义了一个拥塞窗口的概念，最开始会将这个值设置为 1 MSS，意味着在没有收到 ack 的时候只能发送一个报文段，之后每次收到一次 ack，这个窗口的大小就 +1，意味着拥塞窗口会呈指数级不断变大。当然，这里最终的窗口值是取流量控制的窗口值和拥塞窗口的最小值。
	2. 一旦产生超时重发，也就是说，当前 TCP 的拥塞窗口过大导致网络拥堵了，那么此时 TCP 的拥塞窗口又会变成 1 从而避免网络拥塞，但是由于之前的慢启动机制，我们的拥塞窗口又会很快变成原样，因此 TCP 设置了一个慢启动阈值，当触发超时重传时，TCP 会将慢启动阈值设置为当前拥塞窗口的一半。当超过慢启动阈值时，会按照几乎线性增长的形式来增大拥塞窗口。

然而，在某些超时的情况下，我们可以使用快速恢复来减少拥塞窗口突然减小的影响。比如触发快速重传时，TCP 认为这种超时并不严重，因此仅仅是将拥塞窗口变成原来的一般，而不是直接降低为 1。

其他提高网络利用率的方法：延迟应答（发送端发送多次报文的多次 ack 合并为一次 ack），捎带应答（ack 中携带一些返回信息）

当然，延迟应答和 Nagle 一起使用就会有问题，因为 nagle 需要等待 ack，而延迟应答如果收到小报文就会延迟等待，从而延迟 ack 的发送。

## 8. TCP 的半连接队列和全连接队列？

全连接队列的长度由 listen 的 backlog 参数和内核的 `/proc/sys/net/core/somaxconn` 参数决定，取最小值，如果在对方发最后一次 ack 的时候，全连接队列满了，有两种情况，一种是直接丢弃，一种是向对端发送 RST（connection reset by peer）来告知客户端连接建立失败，我们可以通过开启 `tcp_abort_on_overflow` 来做到这一点；默认条件可以提高建立连接的成功率，除非 TCP 队列长期是满的，则可以直接发送 RST 。^e1844c

半连接队列的长度不仅取决于内核的 `tcp_max_syn_backlog`，还和全连接队列的长度有关，逻辑如下： ^408f44
1. 首先判断半连接队列是否满了，半连接的长度 `max_qlen_log` 是上述全连接长度的最小值 * 2，如果满了且没有开启 `tcp_syncookies` 则直接丢弃。
2. 然后看全连接队列是否满了，如果全连接队列满了并且此时发送第一次握手但是没有返回 ack 的连接数大于 1，那么则会丢弃这个连接。
3. 最后看是否开启了 `tcp_syncookies`，如果开启了则直接通过了，如果没有，那么当 `tcp_max_syn_backlog` 减去当前半连接队列的长度小于 `tcp_max_syn_backlog >> 2` 则会丢弃。

由上可知，我们的半连接队列长度取决于 `tcp_max_syn_backlog` 以及全连接的相关队列参数。

顺便一提，TCP 的半连接队列实际上是一个哈希表，而全连接队列才是一个真正的链表，原因是我们第三次握手需要快速找到之前建立的半连接对象，而全连接队列只需要通过 accept() 随便取一个就可以了。

## 9. TCP 的优化？
1. 优化三次握手：
	- 客户端在第一次握手之后，如果没有收到 ack 会反复发送第一次握手，在某些情况下，我们可以通过修改 `tcp_syn_retries` 来减少重试次数，将错误快速反馈给应用层。
	- 服务端在第二次握手之后，如果没有收到 ack，这个还没有完全建立的连接会滞留在半连接队列里面，常见的有 syn 攻击就是攻击的这个半连接队列，我们可以通过上述的[[#^408f44|半连接队列介绍]]来调整半连接队列的大小，同时开启 `tcp_syncookies` 来实现不使用半连接队列的情况下建立连接。
	- 服务端在第三次握手的时候，全连接队列已满，默认会直接丢弃。我们可以通过[[#^e1844c|全连接队列介绍]]提到的方法调整策略以及全连接队列的长度。
	- 可以通过 TCP Fast Open 绕过 TCP 三次握手，快速建立连接，如图所示，当然，这种方法需要客户端和服务端都开启了 FastOpen 才行：
	  ![image](./assets/image1.png)
2. 优化四次挥手
	- 

3. 传输性能提升