# Redis 知识碎片

## 1.大 Key 对 AOF 重写和 RDB 快照的影响

aof 追加大 key 日志的时候，占用空间会增长的比较快，而且如果采取 always 模式，频繁写入大 key 到磁盘会有性能问题。

由于占用空间增长比较快，那么会频繁触发 aof 重写。而此时当然会调用 fork 来实现保存快照，然而如果大 key 过多，页表过大，就会导致 fork 变慢，发生阻塞。而当 fork 之后在重写的过程中，触发了写大 key，由于其占用的物理空间较大，也会导致一定程度的阻塞。

另外一提，当我们为 linux 开启内存大页时，也会影响 redis 的性能，因为此时，如果修改的数据位于大页，即便只有 100 b，也会重新分配整个大页。

除了对持久化有影响之外，大 key 还会造成**客户端侧超时阻塞**，也就是在客户端看来，处理非常慢，阻塞了，很久很久没有响应。

**网络阻塞**，每次获取大 key 的时候产生的网络流量比较大，如果一个大 key 的大小为 1 mb，每秒访问量为 1000，每秒就会产生 1000 mb 的流量。**工作线程阻塞**，delete 删除大 key 的时候会阻塞工作线程，无法执行后续命令。**内存分配不均**，集群模型在哈希槽分配均匀的情况下，会出现数据倾斜的情况。

**如何预防？**

很简单，我们应该在设计阶段就将大 key 拆分成一个个小 key，并且定期检查大 key，使用 unlink 而不是 delete 删除大 key。
针对于哈希表，集合这种多元素的，我们可以选择分批次删除里面的键值对，在 4.0 版本之后，就可以通过 unlink 去进行异步删除大 key 了。

## 2. Redis 的 LRU 和 LFU 的内存淘汰策略是啥样的？

Redis 的 LRU 或者 LFU 并没有为所有键值对维护一条长的要死的链表，而是通过每次随机抽取 5 个键值对，根据 LRU 或者 LFU 淘汰策略，淘汰排在最后的那一个。

LRU 无法解决缓存污染的问题，而 LFU 恰好弥补了这一点，相比于 LRU，LFU 策略中，每个 kv 键值对会多记录一个数据访问频次的字段，这样就有效的防止了一次性读取的大量的临时数据导致缓存污染的问题。

针对于 LFU，记录了上一次访问的时间以及访问的频次，每次访问会根据上一次访问的时间更新访问频次的数据（先减少，再按照一定概率增长）。



## 3. Redis 如何应对主从引发的问题？

主从数据不一致：

- 禁止从库写
- 选主时优先选择 offset 更新的节点。
- 写入返回前等待复制到 N 个从库（这一点类似 raft）

脑裂：

- 必须要多数从节点认为自己是主节点，并且复制延迟不超过一定时间，才能够接受写请求。

## 4. 缓存雪崩和缓存击穿？

缓存雪崩，有两种可能的情况，一种是 redis 故障，一种是大量 KV 同时过期，导致缓存雪崩问题，大量的请求会瞬间涌入 DB。

解决方案：

- 过期时间随机
- 互斥锁，只让一个请求去访问 DB，其余请求等待缓存构建完成或者返回空（小林是这样写的，我认为有一个优化的点，这里不用分布式锁，而是使用限流器，因为如果使用分布式锁，单一的请求可能会阻塞，导致锁无法释放，即便使用租约也会导致性能下降，所以应该同一时间让部分的请求去请求数据，然后其余的请求循环等待缓存的构建，这样可以提高一点性能，除此之外，go 里面还可以使用 singleflight 去优化一下，保证短时间内只有一个请求去重建缓存，其实和狗堆效应解决方案的思想很像）
- 后台缓存更新（感觉这个方案不太好，因为你总不能缓存所有字段，而且你需要统计哪些数据应该定期缓存也需要字段，这也会导致一定成本，造成资源浪费，维护也比较麻烦，同时旁路缓存可能也不好做）

那对于 redis 宕机咋办？

- 服务熔断或者限流
- 构建缓存的集群

那么**缓存击穿**呢？缓存击穿是指热点数据过期了，导致大量请求涌入 DB。

其实思路差不多，也是互斥锁（**dog pile**），除此之外，可以给特定的热点数据不设置更新时间，或者专门安排一个线程后台更新（可能也不好用，徒增系统复杂度）

**缓存穿透**，缓存穿透是指数据既不在缓存，也不在 DB 中，一般是业务错误或者说黑客恶意攻击，解决方案：

- 限制非法请求，直接在 API 入口处判断参数是否合法。
- 缓存空值或者默认值。
- 布隆过滤器快速判断数据是否存在，布隆过滤器是啥？通过对数据进行哈希计算，将对应的数据锁定到对应的位图上，如果当前位上为 1，说明数据存在，否则数据不存在，布隆过滤器不能保证数据一定存在，但是能够保证数据一定不存在。

