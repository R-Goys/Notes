
bitcask 和 LSM 设计上非常相似，都是一种日志结构的存储结构。

bitcask 内部有多个文件，且同一时刻只会将数据追加到一个活跃的文件中，其他文件都是不活跃，也就是 older data file，如果当前活跃文件写满之后，就会新建一个文件继续写入数据，此时新建的文件就是当前的活跃文件。

这样带来的好处就是写入性能非常好，能够充分利用顺序写的优势，那么读取效率呢？bitcask 的存储结构并没有使用 lsm 的分层结构，也不是通过内部自动 compact，总不可能从新到旧依次遍历吧？当然不是，它采取了另一种索引方式——**全内存索引**，他将所有的键的数据存储的文件的最新索引放在内存中，当我们需要查询某个键值的时候，通过这个 keydir 找到这个键的值在磁盘上的最新位置，从而可以直接从磁盘上快速找到这个 key 的最新位置，进而读取到最新的数据。

还有什么问题呢？就是我们的磁盘占用的问题，我们 bitcask 充分利用顺序写的优势，同时我们旧的写入文件肯定有冗余的数据，那么如何消除这些冗余的数据呢？答案是在一定情况下，会对这些 older data file 进行遍历并进行 merge，从而达到压缩数据的目的，而在 merge 的过程中，我们内存索引可能并不是实时有效的，读取会出现一定问题，所以我们可能需要停机、拒绝服务等策略来防止程序出现错误，当然，如果一定要在运行期间实施合并操作，可以选择分阶段 merge，当然由于频繁的磁盘 IO，可能就会影响到工作线程的执行性能了，在 merge 结束之后，还需要原子替换文件，并且根据 merge 文件之后会生成的 hint 文件来重新在内存中快速建立索引，并替换原来打开的旧文件，当然这里阶段我认为是必须要加锁的，所以必然会有一定的影响。

那么总结一下，bitcask 由于其顺序写机制，所以具有极高的写入性能，读取性能也由于内存索引的存在所以也较高，但是其 merge 策略相对比较暴力，并且因为是内存索引，所以可能存储的数据量有一定局限性。常见的 keydir 实现形式是哈希表，但是也可以是其他数据结构，比如跳表、B+树从而实现可以遍历查找。


一个 bitcask KV 实现（提供了多种索引结构）：
https://github.com/wmlhy2324/kv-go