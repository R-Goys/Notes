# Kafka

## 1. Kafka 的顺序写机制？

kafka 的消息都是通过顺序写来持久化的，不需要涉及到复杂的索引，缺点只有无法插入更新这些操作，但是对于一个专注于高吞吐的消息队列来说，这就够了。

与此同时，kafka 的顺序写又恰好天然构成了消息的偏移量，便于消费者精确控制消费进度。

除此之外，Kafka 也不是直接写入磁盘的，而是配合操作系统的 PageCache 机制来异步写入的。当然，读取也是一样，可以直接从 PageCache 中读取。然而，PageCache 在操作系统挂掉，或者断电的时候注定会有一定的不可靠，所以 Kafka 也提供了一个是否异步写入磁盘的选项，可以自己控制写入策略。

## 2. 零拷贝？

零拷贝是通过 `sendfile()` 系统调用将文件里的内容直接发送到 socket 中，即直接将文件数据发送到网络。那么没有零拷贝会发生什么？首先，我们需要 `read` 文件中的数据，然后通过 `write` 写入到 socket 里面，涉及到两次系统调用，同时，我们将磁盘读到内存中还涉及到 DMA 内存拷贝，从内存到网卡，也涉及到 DMA 内存拷贝，最终，传统的方法就会有 4 次内存拷贝的操作。

而有了 `sendfile` 我们就只需要两次内存拷贝，第一次，从磁盘拷贝数据到内存，第二次，将内存中的数据拷贝到网卡，仅此而已，不会涉及到内核到用户空间的内存拷贝，并且只会涉及到一次系统调用，从而提高了性能。

## 3. Kafka 的分层机制

kafka 需要将消息持久化，然而如果所有消息都只写入一个统一的文件，很容易出现瓶颈，所以 Kafka 设计了一个 topic 来隔离不同的业务消息，可以不同 topic 的文件分开，即便如此，也可能出现瓶颈，所以 topic 下还有 partition，每个 partition 单独处理消息的写入和消费，从而能够进行横向扩展，当然，partition 并不只有一个文件，而是会滚动分片的，当一个 segment 文件达到大小限制，就会新开一个文件继续写。

## 4. 批量写操作

即将消息缓存到 buffer 中，等待数量或者时间超过阈值来实现批量发送，可以减少网络开销。生产者可以实现批量发送，消费者也可以批量消费，一次性拉取多条消息进行消费。

除了生产消费，持久化也一样，是批量持久化的模式。

## 5. 数据压缩

数据压缩，常见的压缩算法支持 gzip，snappy，当然这不是重点，生产者会将数据进行压缩之后进行发送，之后一直到消费者才会真正的解析压缩后的数据。

kafka 也支持在 broker 进行压缩，但是建议在客户端进行压缩，如果生产者和 broker 同时开启压缩算法，如果相同，则不会做任何操作，如果不同，则会将数据解析之后用 broker 的压缩算法重新压缩。

## 6. 消息积压如何解决？


消息积压是由生产者的生产速度 > 消费者的消费速度引起的，首先排查是不是 bug，比如消费之后没有 ack，消费者挂了或者是上游没有做限流，导致生产过快之类的，如果是，那么我们在解决 bug 之后，可能需要根据数量紧急扩容，新建一个临时 topic，同时提高 partition 的数量，扩展消费者的节点，从而实现快速消费；如果不是，我们可以选择批量拉取消息并发的去处理，如果还是不行，可以水平扩容，增加消费者节点或者机器的数量，同时提高 partition 的数量，从而提高吞吐量。

当然也可能是大量的消息由于业务问题消费失败从而无法正常 ack，导致引起了重试风暴，当然，这个只需要解决了业务问题就可以了。

如果消费者端已经到达了消费瓶颈，我们可以对消费者端进行一些优化，比如消费者端的上游服务有没有做必要的限流，降级之类的。

其实两种情况解决思路都差不多，重点是我们需要提高消息消费的速度。