# Kafka

## 1. Kafka 的顺序写机制？

kafka 的消息都是通过顺序写来持久化的，不需要涉及到复杂的索引，缺点只有无法插入更新这些操作，但是对于一个专注于高吞吐的消息队列来说，这就够了。

与此同时，kafka 的顺序写又恰好天然构成了消息的偏移量，便于消费者精确控制消费进度。

除此之外，Kafka 也不是直接写入磁盘的，而是配合操作系统的 PageCache 机制来异步写入的。当然，读取也是一样，可以直接从 PageCache 中读取。然而，PageCache 在操作系统挂掉，或者断电的时候注定会有一定的不可靠，所以 Kafka 也提供了一个是否异步写入磁盘的选项，可以自己控制写入策略。

## 2. 零拷贝？

零拷贝是通过 `sendfile()` 系统调用将文件里的内容直接发送到 socket 中，即直接将文件数据发送到网络。那么没有零拷贝会发生什么？首先，我们需要 `read` 文件中的数据，然后通过 `write` 写入到 socket 里面，涉及到两次系统调用，同时，我们将磁盘读到内存中还涉及到 DMA 内存拷贝（值得一提的是，DMA 并不需要 cpu 资源的参与，而是 IO 设备自己拷贝到指定的内存位置），从内存到网卡，也涉及到 DMA 内存拷贝，最终，传统的方法就会有 4 次内存拷贝的操作。

而有了 `sendfile` 我们就只需要两次内存拷贝，第一次，从磁盘拷贝数据到内存，第二次，将内存中的数据拷贝到网卡，仅此而已，不会涉及到内核到用户空间的内存拷贝，并且只会涉及到一次系统调用，从而提高了性能。

## 3. Kafka 的分层机制

kafka 需要将消息持久化，然而如果所有消息都只写入一个统一的文件，很容易出现瓶颈，所以 Kafka 设计了一个 topic 来隔离不同的业务消息，可以不同 topic 的文件分开，即便如此，也可能出现瓶颈，所以 topic 下还有 partition，每个 partition 单独处理消息的写入和消费，从而能够进行横向扩展，当然，partition 并不只有一个文件，而是会滚动分片的，当一个 segment 文件达到大小限制，就会新开一个文件继续写。

## 4. 批量写操作

即将消息缓存到 buffer 中，等待数量或者时间超过阈值来实现批量发送，可以减少网络开销。生产者可以实现批量发送，消费者也可以批量消费，一次性拉取多条消息进行消费。

除了生产消费，持久化也一样，是批量持久化的模式。

## 5. 数据压缩

数据压缩，常见的压缩算法支持 gzip，snappy，当然这不是重点，生产者会将数据进行压缩之后进行发送，之后一直到消费者才会真正的解析压缩后的数据。

kafka 也支持在 broker 进行压缩，但是建议在客户端进行压缩，如果生产者和 broker 同时开启压缩算法，如果相同，则不会做任何操作，如果不同，则会将数据解析之后用 broker 的压缩算法重新压缩。

## 6. 消息积压如何解决？


消息积压是由生产者的生产速度 > 消费者的消费速度引起的，一般来说，可能是消费者生产过快，或者消费者消费过慢导致的，当然也可能是代码或者业务层面的 bug。

首先排查是不是 bug，比如消费之后没有 ack，消费者挂了或者是上游没有做限流，导致生产过快之类的，如果是，那么我们在解决 bug 之后，可能需要根据数量紧急扩容，新建一个临时 topic，同时提高 partition 的数量，扩展消费者的节点，从而实现快速消费；如果不是，我们可以选择批量拉取消息并发的去处理，如果还是不行，可以水平扩容，增加消费者节点或者机器的数量，同时提高 partition 的数量，从而提高吞吐量。

当然也可能是大量的消息由于业务问题消费失败从而无法正常 ack，导致引起了重试风暴，当然，这个只需要解决了业务问题就可以了。

如果消费者端已经到达了消费瓶颈，我们可以对生产者端进行一些优化，比如生产者端的上游服务有没有做必要的限流，降级之类的；当然，我们也可以看看消费者有没有可能继续优化，比如我们当前的消费可能是订单数据写入数据库，发送短信通知，调用物流服务..此时我们可以独立多个消费者组，进行并行消费。

我们还可以将不同业务的消息队列集群独立开来，单独用一个集群去处理不同重要性的业务，可以防止比如日志这种内容把订单消息阻塞了。

最后，还可以将消息进行优化，保留必要字段来减少传输和序列化反序列化的开销。

## 7. 如何保证消息不会重复消费？

引起重复消费有两种情况：
1. 生产者重复发送，常见比如网络波动，重试发送。
2. 消费者没有及时提交 offset，重复消费，亦或是生产者发送了多次消息导致重复消费。

一般来说，解决重复消费一般是交给消费端做接口幂等，但是生产者也可以做一定的优化，但是最终有一些情况依旧需要依赖于消费者的处理。

**生产者**：没啥难的，直接启用一个 `enable.idempotence` 参数，表示开启幂等性生产，他通过三个机制去重：
1. 通过分配 producerId 来区分消费者。
2. 生产者会为每条消息分配单调递增的序列号，
3. broker 的消息去重校验，只有当接受消息的序列号等于当前分区的最大序列号 + 1才会正常接受，如果跳过或者重复都会被拒绝。

**消费者**：保证不重复消费最核心的手段就是让幂等消费，我们可以根据业务来选择方法：
1. outbox，消息携带 outbox 中的唯一 id，如果查询到这个字段已经消费，则丢弃，其实解决方案大多都是这个思想。
2. 版本号控制。
3. 对需要进行修改的数据库字段设置状态机流转，比如订单的状态机有：未付款，已付款，已过期，当检测到当前状态不符合期望，或者说状态已经被修改成将要修改的状态，直接丢弃。

## 8. 如何保证消息有序？

kafka 保证单分区有序，无法保证多分区有序，所以我们可以自定义分区策略，将希望有序的消息转发到一个分区中。

八股文里面说的在客户端做排序策略理论上感觉不太行。

## 9. kafka 如何保证的高可用性？

kafka 作为分布式消息队列，为了确保其高可用性，有一些容灾策略。

比如多副本机制，当分区的 leader 写入数据之后，会将数据同步到对应分区的 follower 中，以此来冗余备份，这就叫作 AR，对于同步数据和 leader 接近的，会放入 ISR 中，而差距较大的就叫 OSR，当我们的 leader 挂了，当前分区就会先从 ISR 中选主，如果 ISR 没有可用的副本，默认会让当前分区直接不可用，如果开启了 unclean 参数，那就可以从 OSR 中选取 leader；在选 leader 时，会尽量选取同步数据更完整的副本。
